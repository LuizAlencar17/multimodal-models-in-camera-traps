{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "MAPPER = {\n",
    "  'species': {\n",
    "    0: 'hyena',\n",
    "    1: 'zebra',\n",
    "    2: 'giraffe',\n",
    "    3: 'buffalo',\n",
    "    4: 'gazelle',\n",
    "    5: 'wildebeest',\n",
    "    6: 'elephant',\n",
    "    7: 'lion',\n",
    "    8: 'bird'\n",
    "  },\n",
    "  'behavior': {\n",
    "    0: 'moving',\n",
    "    1: 'eating',\n",
    "    2: 'resting'\n",
    "  },\n",
    "  'animal': {\n",
    "    0: 'empty',\n",
    "    1: 'animal'\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESULTS ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to determine the task based on the file path\n",
    "def get_task_from_path(path):\n",
    "    if \"species-classifier\" in path:\n",
    "        return \"species\"\n",
    "    elif \"animal-classifier\" in path:\n",
    "        return \"animal\"\n",
    "    elif \"behaviour-classifier\" in path or \"behavior-classifier\" in path:\n",
    "        return \"behavior\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "# Load CSV data and add task and model information\n",
    "def load_model_data(model_list):\n",
    "    model_data = []\n",
    "    for entry in model_list:\n",
    "        results_path = entry[\"results_path\"]\n",
    "        model = entry[\"model\"]\n",
    "        task = get_task_from_path(results_path)\n",
    "        \n",
    "        if os.path.exists(results_path):\n",
    "            df = pd.read_csv(results_path)\n",
    "            \n",
    "            # Ensure 'pred' and 'real' are of consistent types\n",
    "            df['pred'] = df['pred'].astype(str)  # Convert predictions to strings\n",
    "            df['real'] = df['real'].astype(str)  # Convert ground truth to strings\n",
    "            \n",
    "            df['model'] = model\n",
    "            df['task'] = task\n",
    "            model_data.append(df)\n",
    "        else:\n",
    "            print(f\"Warning: File not found - {results_path}\")\n",
    "    return pd.concat(model_data, ignore_index=True) if model_data else pd.DataFrame()\n",
    "\n",
    "# Calculate metrics for a group (by task and model)\n",
    "def calculate_metrics_for_group(df):\n",
    "    pred = df['pred']\n",
    "    real = df['real']\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(real, pred),\n",
    "        'precision': precision_score(real, pred, average='weighted', zero_division=0),\n",
    "        'recall': recall_score(real, pred, average='weighted', zero_division=0),\n",
    "        'f1_score': f1_score(real, pred, average='weighted', zero_division=0)\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "# Aggregate metrics by task and model\n",
    "def evaluate_models(data):\n",
    "    grouped_metrics = []\n",
    "    for (task, model), group in data.groupby(['task', 'model']):\n",
    "        metrics = calculate_metrics_for_group(group)\n",
    "        metrics.update({'task': task, 'model': model})\n",
    "        grouped_metrics.append(metrics)\n",
    "    return pd.DataFrame(grouped_metrics)\n",
    "\n",
    "# Visualize metrics with vertical model names in data labels\n",
    "def visualize_model_performance(metrics_df, metric_name=\"accuracy\"):\n",
    "    # Pivot the metrics dataframe for easier plotting\n",
    "    pivot_table = metrics_df.pivot(index='task', columns='model', values=metric_name)\n",
    "\n",
    "    # Define parameters for bar placement and width\n",
    "    bar_width = 0.15  # Width of each individual bar\n",
    "    group_width = bar_width * len(pivot_table.columns) + 0.2  # Space for each group\n",
    "    x = np.arange(len(pivot_table)) * group_width  # Adjust group spacing\n",
    "\n",
    "    # Create the figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "    # Plot each model's bar with adjusted positions\n",
    "    for i, model in enumerate(pivot_table.columns):\n",
    "        positions = x + i * bar_width  # Offset for each model within the group\n",
    "        ax.bar(\n",
    "            positions,\n",
    "            pivot_table[model],\n",
    "            bar_width,\n",
    "            label=model,\n",
    "            edgecolor='black',\n",
    "            alpha=0.85\n",
    "        )\n",
    "\n",
    "        # Add data labels\n",
    "        for pos, value in zip(positions, pivot_table[model]):\n",
    "            ax.text(\n",
    "                pos, value + 0.01, \n",
    "                f\"{value:.2f}\", \n",
    "                fontsize=10, ha='center', va='bottom'\n",
    "            )\n",
    "\n",
    "    # Customize the chart aesthetics\n",
    "    ax.set_title(f\"Model Performance by Task ({metric_name.capitalize()})\", fontsize=16, fontweight='bold')\n",
    "    ax.set_xlabel(\"Task\", fontsize=14)\n",
    "    ax.set_ylabel(metric_name.capitalize(), fontsize=14)\n",
    "    ax.set_xticks(x + (len(pivot_table.columns) - 1) * bar_width / 2)  # Center tick under group\n",
    "    ax.set_xticklabels(pivot_table.index, rotation=45, ha='right', fontsize=12)\n",
    "    ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))  # Convert to percentage if applicable\n",
    "    ax.legend(title=\"Model\", fontsize=12, title_fontsize=14, loc=\"upper left\", bbox_to_anchor=(1.05, 1))\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def replace_text(df, column_name):\n",
    "    def replace_value(value):\n",
    "        try:\n",
    "            float(value)\n",
    "            return value \n",
    "        except (ValueError, TypeError):\n",
    "            return \"-1\"\n",
    "    df[column_name] = df[column_name].apply(replace_value)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of models and results\n",
    "model_list = [\n",
    "    {\"results_path\": \"/data/luiz/dataset/results/behaviour-classifier/blip_serengeti_-.csv\", \"model\": \"BLIP\"},\n",
    "    {\"results_path\": \"/data/luiz/dataset/results/behaviour-classifier/blip_serengeti_pretrained.csv\", \"model\": \"BLIP-FewShot\"},\n",
    "    {\"results_path\": \"/data/luiz/dataset/results/behaviour-classifier/clip_serengeti_-.csv\", \"model\": \"CLIP\"},\n",
    "    {\"results_path\": \"/data/luiz/dataset/results/behaviour-classifier/clip_serengeti_pretrained.csv\", \"model\": \"CLIP-FewShot\"},\n",
    "    {\"results_path\": \"/data/luiz/dataset/results/behaviour-classifier/gpt_serengeti_-.csv\", \"model\": \"GPT\"},\n",
    "    {\"results_path\": \"/data/luiz/dataset/results/behaviour-classifier/gemini_serengeti_-.csv\", \"model\": \"GEMINI\"},\n",
    "\n",
    "    {\"results_path\": \"/data/luiz/dataset/results/behaviour-classifier/blip_serengeti_seq.csv\", \"model\": \"BLIP-Seq\"},\n",
    "    {\"results_path\": \"/data/luiz/dataset/results/behaviour-classifier/blip_serengeti_pretrained-seq.csv\", \"model\": \"BLIP-FewShot-Seq\"},\n",
    "    {\"results_path\": \"/data/luiz/dataset/results/behaviour-classifier/clip_serengeti_seq.csv\", \"model\": \"CLIP-Seq\"},\n",
    "    {\"results_path\": \"/data/luiz/dataset/results/behaviour-classifier/clip_serengeti_pretrained-seq.csv\", \"model\": \"CLIP-FewShot-Seq\"},\n",
    "    {\"results_path\": \"/data/luiz/dataset/results/behaviour-classifier/gpt_serengeti_seq.csv\", \"model\": \"GPT-Seq\"},\n",
    "    {\"results_path\": \"/data/luiz/dataset/results/behaviour-classifier/gemini_serengeti_seq.csv\", \"model\": \"GEMINI-Seq\"},\n",
    "\n",
    "    {\"results_path\": \"/data/luiz/dataset/results/animal-classifier/blip_serengeti_-.csv\", \"model\": \"BLIP\"},\n",
    "    {\"results_path\": \"/data/luiz/dataset/results/animal-classifier/blip_serengeti_pretrained.csv\", \"model\": \"BLIP-FewShot\"},\n",
    "    {\"results_path\": \"/data/luiz/dataset/results/animal-classifier/clip_serengeti_-.csv\", \"model\": \"CLIP\"},\n",
    "    {\"results_path\": \"/data/luiz/dataset/results/animal-classifier/clip_serengeti_pretrained.csv\", \"model\": \"CLIP-FewShot\"},\n",
    "    {\"results_path\": \"/data/luiz/dataset/results/animal-classifier/gpt_serengeti_-.csv\", \"model\": \"GPT\"},\n",
    "    {\"results_path\": \"/data/luiz/dataset/results/animal-classifier/gemini_serengeti_-.csv\", \"model\": \"GEMINI\"},\n",
    "\n",
    "\n",
    "    {\"results_path\": \"/data/luiz/dataset/results/species-classifier/blip_serengeti_-.csv\", \"model\": \"BLIP\"},\n",
    "    {\"results_path\": \"/data/luiz/dataset/results/species-classifier/blip_serengeti_pretrained.csv\", \"model\": \"BLIP-FewShot\"},\n",
    "    {\"results_path\": \"/data/luiz/dataset/results/species-classifier/clip_serengeti_-.csv\", \"model\": \"CLIP\"},\n",
    "    {\"results_path\": \"/data/luiz/dataset/results/species-classifier/clip_serengeti_pretrained.csv\", \"model\": \"CLIP-FewShot\"},\n",
    "    {\"results_path\": \"/data/luiz/dataset/results/species-classifier/gpt_serengeti_-.csv\", \"model\": \"GPT\"},\n",
    "    {\"results_path\": \"/data/luiz/dataset/results/species-classifier/gemini_serengeti_-.csv\", \"model\": \"GEMINI\"},\n",
    "    {\"results_path\": \"/data/luiz/dataset/results/species-classifier/gemini_serengeti_-.csv\", \"model\": \"GEMINI\"},\n",
    "    {\"results_path\": \"/data/luiz/dataset/results/species-classifier/gemini_serengeti_-.csv\", \"model\": \"GEMINI\"},\n",
    "]\n",
    "\n",
    "# Load data\n",
    "data = load_model_data(model_list)\n",
    "data = replace_text(data, \"pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute classification metrics for each model and task\n",
    "def compute_metrics_by_class(df):\n",
    "    grouped_metrics = []\n",
    "\n",
    "    for (model, task), group in df.groupby(['model', 'task']):\n",
    "        # Get unique labels for this task only\n",
    "        labels = list(set(group['real']))\n",
    "        \n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            group['real'], group['pred'], labels=labels, zero_division=0\n",
    "        )\n",
    "        for label, p, r, f in zip(labels, precision, recall, f1):\n",
    "            grouped_metrics.append({\n",
    "                'model': model,\n",
    "                'task': task,\n",
    "                'class': label,\n",
    "                'precision': round(p, 4),\n",
    "                'recall': round(r, 4),\n",
    "                'f1_score': round(f, 4)\n",
    "            })\n",
    "    return pd.DataFrame(grouped_metrics)\n",
    "\n",
    "def compute_metrics(df):\n",
    "    # Group by model and task\n",
    "    grouped = df.groupby(['model', 'task'])\n",
    "    results = []\n",
    "\n",
    "    # Iterate through each group\n",
    "    for (model, task), group in grouped:\n",
    "        y_true = group['real']\n",
    "        y_pred = group['pred']\n",
    "        \n",
    "        # Compute metrics (assuming classification and labels are binary or multiclass)\n",
    "        precision = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "        recall = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "        f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "        \n",
    "        results.append({\n",
    "            'model': model,\n",
    "            'task': task,\n",
    "            'precision': round(precision, 4),\n",
    "            'recall': round(recall, 4),\n",
    "            'f1_score': round(f1, 4)\n",
    "        })\n",
    "\n",
    "    # Convert results to a DataFrame\n",
    "    metrics_df = pd.DataFrame(results)\n",
    "    return metrics_df\n",
    "\n",
    "metrics_df = compute_metrics(data)\n",
    "metrics_df_by_class = compute_metrics_by_class(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>task</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BLIP</td>\n",
       "      <td>animal</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BLIP</td>\n",
       "      <td>behavior</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BLIP</td>\n",
       "      <td>species</td>\n",
       "      <td>0.1861</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BLIP-FewShot</td>\n",
       "      <td>animal</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>0.9100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BLIP-FewShot</td>\n",
       "      <td>behavior</td>\n",
       "      <td>0.7041</td>\n",
       "      <td>0.7011</td>\n",
       "      <td>0.7011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BLIP-FewShot</td>\n",
       "      <td>species</td>\n",
       "      <td>0.7684</td>\n",
       "      <td>0.7532</td>\n",
       "      <td>0.7556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BLIP-FewShot-Seq</td>\n",
       "      <td>behavior</td>\n",
       "      <td>0.7640</td>\n",
       "      <td>0.7555</td>\n",
       "      <td>0.7567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BLIP-Seq</td>\n",
       "      <td>behavior</td>\n",
       "      <td>0.1073</td>\n",
       "      <td>0.0653</td>\n",
       "      <td>0.0812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CLIP</td>\n",
       "      <td>animal</td>\n",
       "      <td>0.8150</td>\n",
       "      <td>0.7983</td>\n",
       "      <td>0.7959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CLIP</td>\n",
       "      <td>behavior</td>\n",
       "      <td>0.3348</td>\n",
       "      <td>0.3430</td>\n",
       "      <td>0.3321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CLIP</td>\n",
       "      <td>species</td>\n",
       "      <td>0.5352</td>\n",
       "      <td>0.4580</td>\n",
       "      <td>0.4456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CLIP-FewShot</td>\n",
       "      <td>animal</td>\n",
       "      <td>0.7594</td>\n",
       "      <td>0.7589</td>\n",
       "      <td>0.7587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CLIP-FewShot</td>\n",
       "      <td>behavior</td>\n",
       "      <td>0.4875</td>\n",
       "      <td>0.4824</td>\n",
       "      <td>0.4766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CLIP-FewShot</td>\n",
       "      <td>species</td>\n",
       "      <td>0.3359</td>\n",
       "      <td>0.3201</td>\n",
       "      <td>0.3174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CLIP-FewShot-Seq</td>\n",
       "      <td>behavior</td>\n",
       "      <td>0.5222</td>\n",
       "      <td>0.5007</td>\n",
       "      <td>0.5016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CLIP-Seq</td>\n",
       "      <td>behavior</td>\n",
       "      <td>0.3431</td>\n",
       "      <td>0.3511</td>\n",
       "      <td>0.3397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GEMINI</td>\n",
       "      <td>animal</td>\n",
       "      <td>0.5695</td>\n",
       "      <td>0.5551</td>\n",
       "      <td>0.5536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GEMINI</td>\n",
       "      <td>behavior</td>\n",
       "      <td>0.4533</td>\n",
       "      <td>0.4312</td>\n",
       "      <td>0.3940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GEMINI</td>\n",
       "      <td>species</td>\n",
       "      <td>0.6912</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>0.6859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>GEMINI-Seq</td>\n",
       "      <td>behavior</td>\n",
       "      <td>0.5002</td>\n",
       "      <td>0.4616</td>\n",
       "      <td>0.4336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GPT</td>\n",
       "      <td>animal</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.8562</td>\n",
       "      <td>0.8552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>GPT</td>\n",
       "      <td>behavior</td>\n",
       "      <td>0.6339</td>\n",
       "      <td>0.4813</td>\n",
       "      <td>0.4195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>GPT</td>\n",
       "      <td>species</td>\n",
       "      <td>0.7036</td>\n",
       "      <td>0.6190</td>\n",
       "      <td>0.6296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>GPT-Seq</td>\n",
       "      <td>behavior</td>\n",
       "      <td>0.4886</td>\n",
       "      <td>0.4053</td>\n",
       "      <td>0.3351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model      task  precision  recall  f1_score\n",
       "0               BLIP    animal     0.0464  0.0118    0.0188\n",
       "1               BLIP  behavior     0.1250  0.0008    0.0016\n",
       "2               BLIP   species     0.1861  0.0005    0.0011\n",
       "3       BLIP-FewShot    animal     0.9100  0.9100    0.9100\n",
       "4       BLIP-FewShot  behavior     0.7041  0.7011    0.7011\n",
       "5       BLIP-FewShot   species     0.7684  0.7532    0.7556\n",
       "6   BLIP-FewShot-Seq  behavior     0.7640  0.7555    0.7567\n",
       "7           BLIP-Seq  behavior     0.1073  0.0653    0.0812\n",
       "8               CLIP    animal     0.8150  0.7983    0.7959\n",
       "9               CLIP  behavior     0.3348  0.3430    0.3321\n",
       "10              CLIP   species     0.5352  0.4580    0.4456\n",
       "11      CLIP-FewShot    animal     0.7594  0.7589    0.7587\n",
       "12      CLIP-FewShot  behavior     0.4875  0.4824    0.4766\n",
       "13      CLIP-FewShot   species     0.3359  0.3201    0.3174\n",
       "14  CLIP-FewShot-Seq  behavior     0.5222  0.5007    0.5016\n",
       "15          CLIP-Seq  behavior     0.3431  0.3511    0.3397\n",
       "16            GEMINI    animal     0.5695  0.5551    0.5536\n",
       "17            GEMINI  behavior     0.4533  0.4312    0.3940\n",
       "18            GEMINI   species     0.6912  0.6837    0.6859\n",
       "19        GEMINI-Seq  behavior     0.5002  0.4616    0.4336\n",
       "20               GPT    animal     0.8693  0.8562    0.8552\n",
       "21               GPT  behavior     0.6339  0.4813    0.4195\n",
       "22               GPT   species     0.7036  0.6190    0.6296\n",
       "23           GPT-Seq  behavior     0.4886  0.4053    0.3351"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>task</th>\n",
       "      <th>class</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BLIP</td>\n",
       "      <td>animal</td>\n",
       "      <td>empty</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BLIP</td>\n",
       "      <td>animal</td>\n",
       "      <td>animal</td>\n",
       "      <td>0.6030</td>\n",
       "      <td>0.1528</td>\n",
       "      <td>0.2438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BLIP</td>\n",
       "      <td>behavior</td>\n",
       "      <td>moving</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BLIP</td>\n",
       "      <td>behavior</td>\n",
       "      <td>resting</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BLIP</td>\n",
       "      <td>behavior</td>\n",
       "      <td>eating</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>GPT</td>\n",
       "      <td>species</td>\n",
       "      <td>gazelle</td>\n",
       "      <td>0.9205</td>\n",
       "      <td>0.7535</td>\n",
       "      <td>0.8286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>GPT</td>\n",
       "      <td>species</td>\n",
       "      <td>giraffe</td>\n",
       "      <td>0.9716</td>\n",
       "      <td>0.8368</td>\n",
       "      <td>0.8992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>GPT</td>\n",
       "      <td>species</td>\n",
       "      <td>zebra</td>\n",
       "      <td>0.7458</td>\n",
       "      <td>0.7525</td>\n",
       "      <td>0.7491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>GPT</td>\n",
       "      <td>species</td>\n",
       "      <td>wildebeest</td>\n",
       "      <td>0.7943</td>\n",
       "      <td>0.4991</td>\n",
       "      <td>0.6130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>GPT-Seq</td>\n",
       "      <td>behavior</td>\n",
       "      <td>moving</td>\n",
       "      <td>0.3654</td>\n",
       "      <td>0.8398</td>\n",
       "      <td>0.5092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      model      task       class  precision  recall  f1_score\n",
       "0      BLIP    animal       empty     0.0000  0.0000    0.0000\n",
       "1      BLIP    animal      animal     0.6030  0.1528    0.2438\n",
       "2      BLIP  behavior      moving     0.5000  0.0033    0.0066\n",
       "3      BLIP  behavior     resting     0.0000  0.0000    0.0000\n",
       "4      BLIP  behavior      eating     0.0000  0.0000    0.0000\n",
       "..      ...       ...         ...        ...     ...       ...\n",
       "95      GPT   species     gazelle     0.9205  0.7535    0.8286\n",
       "96      GPT   species     giraffe     0.9716  0.8368    0.8992\n",
       "97      GPT   species       zebra     0.7458  0.7525    0.7491\n",
       "98      GPT   species  wildebeest     0.7943  0.4991    0.6130\n",
       "99  GPT-Seq  behavior      moving     0.3654  0.8398    0.5092\n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df_by_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping function\n",
    "def map_class_labels(row, mapper):\n",
    "    task = row['task']\n",
    "    class_value = row['class']\n",
    "    return mapper.get(task, {}).get(int(class_value), class_value)  # Keep original if not found\n",
    "\n",
    "# Apply the mapping\n",
    "metrics_df_by_class['class'] = metrics_df_by_class.apply(lambda row: map_class_labels(row, MAPPER), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"model\": \"BLIP\", \"class\": \"0\", \"recall\": 0.0033}, {\"model\": \"BLIP\", \"class\": \"2\", \"recall\": 0.0}, {\"model\": \"BLIP\", \"class\": \"1\", \"recall\": 0.0}, {\"model\": \"BLIP-FewShot\", \"class\": \"0\", \"recall\": 0.662}, {\"model\": \"BLIP-FewShot\", \"class\": \"2\", \"recall\": 0.6706}, {\"model\": \"BLIP-FewShot\", \"class\": \"1\", \"recall\": 0.7707}, {\"model\": \"BLIP-FewShot-Seq\", \"class\": \"0\", \"recall\": 0.7392}, {\"model\": \"BLIP-FewShot-Seq\", \"class\": \"2\", \"recall\": 0.7232}, {\"model\": \"BLIP-FewShot-Seq\", \"class\": \"1\", \"recall\": 0.804}, {\"model\": \"BLIP-Seq\", \"class\": \"0\", \"recall\": 0.0}, {\"model\": \"BLIP-Seq\", \"class\": \"2\", \"recall\": 0.0}, {\"model\": \"BLIP-Seq\", \"class\": \"1\", \"recall\": 0.2614}, {\"model\": \"CLIP\", \"class\": \"0\", \"recall\": 0.4886}, {\"model\": \"CLIP\", \"class\": \"2\", \"recall\": 0.3497}, {\"model\": \"CLIP\", \"class\": \"1\", \"recall\": 0.1909}, {\"model\": \"CLIP-FewShot\", \"class\": \"0\", \"recall\": 0.5436}, {\"model\": \"CLIP-FewShot\", \"class\": \"2\", \"recall\": 0.5748}, {\"model\": \"CLIP-FewShot\", \"class\": \"1\", \"recall\": 0.3289}, {\"model\": \"CLIP-FewShot-Seq\", \"class\": \"0\", \"recall\": 0.5995}, {\"model\": \"CLIP-FewShot-Seq\", \"class\": \"2\", \"recall\": 0.4584}, {\"model\": \"CLIP-FewShot-Seq\", \"class\": \"1\", \"recall\": 0.4442}, {\"model\": \"CLIP-Seq\", \"class\": \"0\", \"recall\": 0.506}, {\"model\": \"CLIP-Seq\", \"class\": \"2\", \"recall\": 0.35}, {\"model\": \"CLIP-Seq\", \"class\": \"1\", \"recall\": 0.1974}, {\"model\": \"GEMINI\", \"class\": \"0\", \"recall\": 0.7464}, {\"model\": \"GEMINI\", \"class\": \"2\", \"recall\": 0.1532}, {\"model\": \"GEMINI\", \"class\": \"1\", \"recall\": 0.8252}, {\"model\": \"GEMINI-Seq\", \"class\": \"0\", \"recall\": 0.7596}, {\"model\": \"GEMINI-Seq\", \"class\": \"2\", \"recall\": 0.2239}, {\"model\": \"GEMINI-Seq\", \"class\": \"1\", \"recall\": 0.8629}, {\"model\": \"GPT\", \"class\": \"0\", \"recall\": 0.9026}, {\"model\": \"GPT\", \"class\": \"2\", \"recall\": 0.0731}, {\"model\": \"GPT\", \"class\": \"1\", \"recall\": 0.468}, {\"model\": \"GPT-Seq\", \"class\": \"0\", \"recall\": 0.8398}, {\"model\": \"GPT-Seq\", \"class\": \"2\", \"recall\": 0.0496}, {\"model\": \"GPT-Seq\", \"class\": \"1\", \"recall\": 0.3265}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def convert_to_json(df):\n",
    "    return json.dumps(df.to_dict(orient=\"records\"))\n",
    "\n",
    "def filter_results(task, metrics):\n",
    "    response = metrics_df_by_class[metrics_df_by_class[\"task\"] == task][['model', 'class', metrics]]\n",
    "    return convert_to_json(response)\n",
    "\n",
    "print(filter_results('behavior', 'recall'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"model\": \"BLIP\", \"class\": \"0\", \"recall\": 0.0}, {\"model\": \"BLIP\", \"class\": \"7\", \"recall\": 0.0027}, {\"model\": \"BLIP\", \"class\": \"8\", \"recall\": 0.0}, {\"model\": \"BLIP\", \"class\": \"3\", \"recall\": 0.0}, {\"model\": \"BLIP\", \"class\": \"6\", \"recall\": 0.0}, {\"model\": \"BLIP\", \"class\": \"4\", \"recall\": 0.0}, {\"model\": \"BLIP\", \"class\": \"2\", \"recall\": 0.0018}, {\"model\": \"BLIP\", \"class\": \"1\", \"recall\": 0.0009}, {\"model\": \"BLIP\", \"class\": \"5\", \"recall\": 0.0}, {\"model\": \"BLIP-FewShot\", \"class\": \"0\", \"recall\": 0.8575}, {\"model\": \"BLIP-FewShot\", \"class\": \"7\", \"recall\": 0.8}, {\"model\": \"BLIP-FewShot\", \"class\": \"8\", \"recall\": 0.669}, {\"model\": \"BLIP-FewShot\", \"class\": \"3\", \"recall\": 0.5669}, {\"model\": \"BLIP-FewShot\", \"class\": \"6\", \"recall\": 0.8058}, {\"model\": \"BLIP-FewShot\", \"class\": \"4\", \"recall\": 0.7991}, {\"model\": \"BLIP-FewShot\", \"class\": \"2\", \"recall\": 0.8812}, {\"model\": \"BLIP-FewShot\", \"class\": \"1\", \"recall\": 0.6535}, {\"model\": \"BLIP-FewShot\", \"class\": \"5\", \"recall\": 0.746}, {\"model\": \"CLIP\", \"class\": \"0\", \"recall\": 0.6018}, {\"model\": \"CLIP\", \"class\": \"7\", \"recall\": 0.1893}, {\"model\": \"CLIP\", \"class\": \"8\", \"recall\": 0.1038}, {\"model\": \"CLIP\", \"class\": \"3\", \"recall\": 0.2518}, {\"model\": \"CLIP\", \"class\": \"6\", \"recall\": 0.5378}, {\"model\": \"CLIP\", \"class\": \"4\", \"recall\": 0.7051}, {\"model\": \"CLIP\", \"class\": \"2\", \"recall\": 0.5249}, {\"model\": \"CLIP\", \"class\": \"1\", \"recall\": 0.4797}, {\"model\": \"CLIP\", \"class\": \"5\", \"recall\": 0.7273}, {\"model\": \"CLIP-FewShot\", \"class\": \"0\", \"recall\": 0.5283}, {\"model\": \"CLIP-FewShot\", \"class\": \"7\", \"recall\": 0.3547}, {\"model\": \"CLIP-FewShot\", \"class\": \"8\", \"recall\": 0.1233}, {\"model\": \"CLIP-FewShot\", \"class\": \"3\", \"recall\": 0.2579}, {\"model\": \"CLIP-FewShot\", \"class\": \"6\", \"recall\": 0.3277}, {\"model\": \"CLIP-FewShot\", \"class\": \"4\", \"recall\": 0.2502}, {\"model\": \"CLIP-FewShot\", \"class\": \"2\", \"recall\": 0.476}, {\"model\": \"CLIP-FewShot\", \"class\": \"1\", \"recall\": 0.207}, {\"model\": \"CLIP-FewShot\", \"class\": \"5\", \"recall\": 0.3556}, {\"model\": \"GEMINI\", \"class\": \"0\", \"recall\": 0.7469}, {\"model\": \"GEMINI\", \"class\": \"7\", \"recall\": 0.8107}, {\"model\": \"GEMINI\", \"class\": \"8\", \"recall\": 0.6291}, {\"model\": \"GEMINI\", \"class\": \"3\", \"recall\": 0.7685}, {\"model\": \"GEMINI\", \"class\": \"6\", \"recall\": 0.8319}, {\"model\": \"GEMINI\", \"class\": \"4\", \"recall\": 0.7758}, {\"model\": \"GEMINI\", \"class\": \"2\", \"recall\": 0.8821}, {\"model\": \"GEMINI\", \"class\": \"1\", \"recall\": 0.7795}, {\"model\": \"GEMINI\", \"class\": \"5\", \"recall\": 0.6123}, {\"model\": \"GPT\", \"class\": \"0\", \"recall\": 0.9442}, {\"model\": \"GPT\", \"class\": \"7\", \"recall\": 0.5289}, {\"model\": \"GPT\", \"class\": \"8\", \"recall\": 0.4037}, {\"model\": \"GPT\", \"class\": \"3\", \"recall\": 0.713}, {\"model\": \"GPT\", \"class\": \"6\", \"recall\": 0.7582}, {\"model\": \"GPT\", \"class\": \"4\", \"recall\": 0.7535}, {\"model\": \"GPT\", \"class\": \"2\", \"recall\": 0.8368}, {\"model\": \"GPT\", \"class\": \"1\", \"recall\": 0.7525}, {\"model\": \"GPT\", \"class\": \"5\", \"recall\": 0.4991}]\n"
     ]
    }
   ],
   "source": [
    "print(filter_results('species', 'recall'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"model\": \"BLIP\", \"class\": \"0\", \"recall\": 0.0}, {\"model\": \"BLIP\", \"class\": \"1\", \"recall\": 0.1528}, {\"model\": \"BLIP-FewShot\", \"class\": \"0\", \"recall\": 0.9081}, {\"model\": \"BLIP-FewShot\", \"class\": \"1\", \"recall\": 0.9119}, {\"model\": \"CLIP\", \"class\": \"0\", \"recall\": 0.9125}, {\"model\": \"CLIP\", \"class\": \"1\", \"recall\": 0.684}, {\"model\": \"CLIP-FewShot\", \"class\": \"0\", \"recall\": 0.735}, {\"model\": \"CLIP-FewShot\", \"class\": \"1\", \"recall\": 0.7828}, {\"model\": \"GEMINI\", \"class\": \"0\", \"recall\": 0.7115}, {\"model\": \"GEMINI\", \"class\": \"1\", \"recall\": 0.9538}, {\"model\": \"GPT\", \"class\": \"0\", \"recall\": 0.949}, {\"model\": \"GPT\", \"class\": \"1\", \"recall\": 0.7635}]\n"
     ]
    }
   ],
   "source": [
    "print(filter_results('animal', 'recall'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATASET ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Task: animal-classifier, Subset: val\n",
      "yes    1538\n",
      "no     1462\n",
      "Name: category, dtype: int64\n",
      "\n",
      "Task: animal-classifier, Subset: test\n",
      "no     5019\n",
      "yes    4981\n",
      "Name: category, dtype: int64\n",
      "\n",
      "Task: animal-classifier, Subset: train\n",
      "yes    10114\n",
      "no      9886\n",
      "Name: category, dtype: int64\n",
      "\n",
      "Task: behaviour-classifier, Subset: val\n",
      "moving     1033\n",
      "resting     988\n",
      "eating      979\n",
      "Name: category, dtype: int64\n",
      "\n",
      "Task: behaviour-classifier, Subset: test\n",
      "eating     3363\n",
      "moving     3328\n",
      "resting    3309\n",
      "Name: category, dtype: int64\n",
      "\n",
      "Task: behaviour-classifier, Subset: train\n",
      "resting    6732\n",
      "eating     6682\n",
      "moving     6586\n",
      "Name: category, dtype: int64\n",
      "\n",
      "Task: species-classifier, Subset: val\n",
      "gazelle       350\n",
      "hyena         347\n",
      "elephant      341\n",
      "lion          334\n",
      "bird          333\n",
      "buffalo       329\n",
      "zebra         323\n",
      "wildebeest    322\n",
      "giraffe       321\n",
      "Name: category, dtype: int64\n",
      "\n",
      "Task: species-classifier, Subset: test\n",
      "buffalo       1136\n",
      "hyena         1130\n",
      "bird          1127\n",
      "lion          1125\n",
      "wildebeest    1122\n",
      "zebra         1111\n",
      "giraffe       1103\n",
      "gazelle       1075\n",
      "elephant      1071\n",
      "Name: category, dtype: int64\n",
      "\n",
      "Task: species-classifier, Subset: train\n",
      "elephant      2257\n",
      "buffalo       2248\n",
      "zebra         2245\n",
      "gazelle       2238\n",
      "lion          2220\n",
      "hyena         2219\n",
      "wildebeest    2209\n",
      "giraffe       2203\n",
      "bird          2161\n",
      "Name: category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define tasks and subsets\n",
    "tasks = ['animal-classifier', 'behaviour-classifier', 'species-classifier']\n",
    "subsets = ['val', 'test', 'train']\n",
    "\n",
    "# Base directory\n",
    "base_dir = '/data/luiz/dataset/partitions'\n",
    "\n",
    "# Function to count categories\n",
    "def count_categories(task, subset):\n",
    "    file_path = os.path.join(base_dir, task, 'serengeti', f'{subset}.csv')\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        print(f'File not found: {file_path}')\n",
    "        return\n",
    "    \n",
    "    # Read CSV\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Check if 'category' column exists\n",
    "    if 'category' not in df.columns:\n",
    "        print(f'No \"category\" column in {file_path}')\n",
    "        return\n",
    "\n",
    "    # Count the occurrences of each category\n",
    "    category_counts = df['category'].value_counts()\n",
    "\n",
    "    print(f'\\nTask: {task}, Subset: {subset}')\n",
    "    print(category_counts)\n",
    "\n",
    "# Iterate through all tasks and subsets\n",
    "for task in tasks:\n",
    "    for subset in subsets:\n",
    "        count_categories(task, subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VIEWING PREDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Function to check if an image meets the rendering criteria\n",
    "def should_render_image(group):\n",
    "    correct_predictions = (group['pred'] == group['real']).sum()\n",
    "    return correct_predictions == 1\n",
    "\n",
    "# Main code to process the DataFrame and render images\n",
    "def render_images(df):\n",
    "    # Group by 'path' to process predictions per image\n",
    "    grouped = df.groupby('path')\n",
    "    \n",
    "    # Track models for which an image has already been rendered\n",
    "    rendered_models = set()\n",
    "    \n",
    "    for path, group in grouped:\n",
    "        if should_render_image(group):\n",
    "            idxs = group.loc[group['pred'] == group['real']].index\n",
    "            for idx in idxs:\n",
    "                correct_row = df.iloc[idx]\n",
    "                correct_model = correct_row['model']\n",
    "                task_name = correct_row['task']\n",
    "                model_prediction = correct_row['pred']\n",
    "                \n",
    "                if (correct_model, task_name) not in rendered_models and task_name== \"animal\" and correct_model==\"CLIP-FewShot\":\n",
    "                    try:\n",
    "                        # Load the image\n",
    "                        img = Image.open(path)\n",
    "                        \n",
    "                        # Display the image\n",
    "                        plt.figure(figsize=(10, 10))\n",
    "                        plt.imshow(img)\n",
    "                        plt.axis('off')\n",
    "                        plt.title(f\"Task: {task_name}\\nModel: {correct_model}\\nPrediction: {model_prediction}\")\n",
    "                        plt.show()\n",
    "                        \n",
    "                        # Mark the model as rendered\n",
    "                        # rendered_models.add((correct_model, task_name))\n",
    "                        \n",
    "                    except FileNotFoundError:\n",
    "                        print(f\"File not found: {path}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error loading image {path}: {e}\")\n",
    "\n",
    "# render_images(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "luiz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
