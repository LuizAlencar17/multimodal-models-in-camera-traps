{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREPROCESS DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from uuid import uuid4\n",
    "\n",
    "FILE_TYPE = \".JPG\"\n",
    "IMAGES_PATH = \"/data/luiz/dataset/serengeti_images/\"\n",
    "ANNOTATIONS_PATH = \"/data/luiz/dataset/serengeti/SnapshotSerengeti_S1-11_v2.1.json\"\n",
    "SEQUENCE_PATH = \"/ssd/luiz/dataset/sequences/\"\n",
    "RESULTS_PATH = \"/data/luiz/dataset/partitions/\"\n",
    "ANNOTATIONS_PATH_CSV = \"/data/luiz/dataset/serengeti/SnapshotSerengeti_v2_1_annotations.csv\"\n",
    "DATABASE = \"serengeti\"\n",
    "CSV_FIELDS = {\n",
    "    'capture_id': 'id',\n",
    "    'question__standing': 'standing', \n",
    "    'question__resting': 'resting', \n",
    "    'question__moving': 'moving', \n",
    "    'question__eating': 'eating', \n",
    "    'question__interacting': 'interacting'\n",
    "}\n",
    "USE_CSV = True\n",
    "\n",
    "SEED = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17689/2323603510.py:2: DtypeWarning: Columns (8,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_csv = pd.read_csv(ANNOTATIONS_PATH_CSV)[CSV_FIELDS.keys()]\n"
     ]
    }
   ],
   "source": [
    "data = json.load(open(ANNOTATIONS_PATH))\n",
    "\n",
    "if USE_CSV:\n",
    "    df_csv = pd.read_csv(ANNOTATIONS_PATH_CSV)[CSV_FIELDS.keys()]\n",
    "    df_data = pd.DataFrame(data[\"annotations\"])\n",
    "    df_data = pd.merge(df_data, df_csv, left_on='seq_id', right_on='capture_id', how='inner')\n",
    "\n",
    "    df_data = df_data.rename(columns=CSV_FIELDS)\n",
    "    # Remover duplicatas mantendo a primeira ocorrência\n",
    "    df_data = df_data.loc[:, ~df_data.columns.duplicated()]\n",
    "\n",
    "data[\"annotations\"] = df_data.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting sequence mapper\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7429835/7429835 [02:09<00:00, 57528.58it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting categorys\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1033219/1033219 [00:10<00:00, 93973.74it/s]\n"
     ]
    }
   ],
   "source": [
    "ALL_ACTIONS = ['standing', 'resting', 'moving', 'eating', 'interacting']\n",
    "ACTIONS = ['resting', 'moving', 'eating']\n",
    "CATEGORIES_INVALID = [1]\n",
    "MAX_ANIMALS = 1\n",
    "\n",
    "def get_category_from_sequence(sequence):\n",
    "    mapper = {}\n",
    "    for action in ALL_ACTIONS:\n",
    "        for frame in sequence:\n",
    "            mapper[action] = mapper.get(action, 0) + frame.get(action, 0)\n",
    "    return max(mapper, key=mapper.get)\n",
    "\n",
    "def is_valid_frame(frame):\n",
    "    try:\n",
    "        count = int(frame[\"count\"])\n",
    "    except Exception:\n",
    "        count = 0\n",
    "    exist_file = os.path.isfile(frame[\"path\"])\n",
    "    category_invalid = frame[\"category_id\"] in CATEGORIES_INVALID\n",
    "    count_valid = count <= MAX_ANIMALS\n",
    "    if not exist_file or category_invalid or not count_valid:\n",
    "        return False\n",
    "    # for action in ALL_ACTIONS:\n",
    "    #     try:\n",
    "    #         if not frame.get(action) >= 0:\n",
    "    #             return False\n",
    "    #     except Exception:\n",
    "    #         return False\n",
    "    return True\n",
    "\n",
    "def get_sequence_mapper(annotations):\n",
    "    mapper = {}\n",
    "    print(\"getting sequence mapper\")\n",
    "    for item in tqdm(annotations):\n",
    "        id = item.get(\"seq_id\")\n",
    "        item[\"path\"] = f'{IMAGES_PATH}{item[\"image_id\"]}{FILE_TYPE}'\n",
    "        if is_valid_frame(item):\n",
    "            if not mapper.get(id):\n",
    "                mapper[id] = []\n",
    "            mapper[id].append(item)\n",
    "    return mapper\n",
    "\n",
    "def get_frames_sequences(data):\n",
    "    sequence_mapper = get_sequence_mapper(data[\"annotations\"])\n",
    "    events = []\n",
    "    print(\"getting categories\")\n",
    "    for key in tqdm(sequence_mapper.keys()):\n",
    "        frames = sequence_mapper[key]\n",
    "        events.append({\n",
    "            \"num_frames\": len(frames),\n",
    "            \"frames\": frames,\n",
    "            \"datetime\": frames[0][\"datetime\"],\n",
    "            \"category\": get_category_from_sequence(frames)})\n",
    "    return events\n",
    "\n",
    "sequences = get_frames_sequences(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['resting', 'moving', 'eating'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(sequences)\n",
    "df = df[df.num_frames > 1]\n",
    "df = df.replace(\"interacting\", \"moving\").replace(\"standing\", \"resting\")\n",
    "df.category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eating     28968\n",
       "resting    28968\n",
       "moving     28968\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def balance_dataset(df):\n",
    "    dfs = []\n",
    "    size = min(df.category.value_counts())\n",
    "    for category in df.category.unique():\n",
    "        filtered = df[df.category == category].sample(size, random_state=SEED)\n",
    "        dfs.append(filtered)\n",
    "    new_df = pd.concat(dfs).reset_index(drop=True)\n",
    "    return new_df.sample(len(new_df), random_state=SEED).reset_index(drop=True)\n",
    "\n",
    "def get_empty_in_frames(frames):\n",
    "    for frame in frames:\n",
    "        if frame[\"category_id\"] == 0:\n",
    "            return frame[\"path\"]\n",
    "    return None\n",
    "\n",
    "def get_animal_in_frames(frames):\n",
    "    for frame in frames:\n",
    "        if frame[\"category_id\"] != 0:\n",
    "            return frame[\"path\"]\n",
    "    return None\n",
    "\n",
    "df[\"path_empty\"] = df.frames.map(lambda a: get_empty_in_frames(a))\n",
    "df[\"path_animal\"] = df.frames.map(lambda a: get_animal_in_frames(a))\n",
    "\n",
    "df = balance_dataset(df)\n",
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['location'] = df.frames.map(lambda a: a[0]['location'])\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "df['path_seq'] = df.frames.map(lambda a: \",\".join([item[\"path\"] for item in a]))\n",
    "\n",
    "df = df[[\"num_frames\", \"category\", \"location\", \"datetime\", \"path_empty\", \"path_animal\", \"path_seq\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_frames</th>\n",
       "      <th>category</th>\n",
       "      <th>location</th>\n",
       "      <th>datetime</th>\n",
       "      <th>path_empty</th>\n",
       "      <th>path_animal</th>\n",
       "      <th>path_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>eating</td>\n",
       "      <td>G12</td>\n",
       "      <td>2012-11-01 07:24:44</td>\n",
       "      <td>None</td>\n",
       "      <td>/data/luiz/dataset/serengeti_images/S5/G12/G12...</td>\n",
       "      <td>/data/luiz/dataset/serengeti_images/S5/G12/G12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>eating</td>\n",
       "      <td>G02</td>\n",
       "      <td>2011-11-05 13:40:03</td>\n",
       "      <td>None</td>\n",
       "      <td>/data/luiz/dataset/serengeti_images/S3/G02/G02...</td>\n",
       "      <td>/data/luiz/dataset/serengeti_images/S3/G02/G02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>resting</td>\n",
       "      <td>D09</td>\n",
       "      <td>2012-02-12 09:50:56</td>\n",
       "      <td>/data/luiz/dataset/serengeti_images/S4/D09/D09...</td>\n",
       "      <td>None</td>\n",
       "      <td>/data/luiz/dataset/serengeti_images/S4/D09/D09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>resting</td>\n",
       "      <td>G12</td>\n",
       "      <td>2010-09-22 05:45:50</td>\n",
       "      <td>/data/luiz/dataset/serengeti_images/S1/G12/G12...</td>\n",
       "      <td>None</td>\n",
       "      <td>/data/luiz/dataset/serengeti_images/S1/G12/G12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>resting</td>\n",
       "      <td>L05</td>\n",
       "      <td>2012-07-30 12:48:36</td>\n",
       "      <td>/data/luiz/dataset/serengeti_images/S5/L05/L05...</td>\n",
       "      <td>None</td>\n",
       "      <td>/data/luiz/dataset/serengeti_images/S5/L05/L05...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_frames category location            datetime  \\\n",
       "0           3   eating      G12 2012-11-01 07:24:44   \n",
       "1           3   eating      G02 2011-11-05 13:40:03   \n",
       "2           3  resting      D09 2012-02-12 09:50:56   \n",
       "3           3  resting      G12 2010-09-22 05:45:50   \n",
       "4           3  resting      L05 2012-07-30 12:48:36   \n",
       "\n",
       "                                          path_empty  \\\n",
       "0                                               None   \n",
       "1                                               None   \n",
       "2  /data/luiz/dataset/serengeti_images/S4/D09/D09...   \n",
       "3  /data/luiz/dataset/serengeti_images/S1/G12/G12...   \n",
       "4  /data/luiz/dataset/serengeti_images/S5/L05/L05...   \n",
       "\n",
       "                                         path_animal  \\\n",
       "0  /data/luiz/dataset/serengeti_images/S5/G12/G12...   \n",
       "1  /data/luiz/dataset/serengeti_images/S3/G02/G02...   \n",
       "2                                               None   \n",
       "3                                               None   \n",
       "4                                               None   \n",
       "\n",
       "                                            path_seq  \n",
       "0  /data/luiz/dataset/serengeti_images/S5/G12/G12...  \n",
       "1  /data/luiz/dataset/serengeti_images/S3/G02/G02...  \n",
       "2  /data/luiz/dataset/serengeti_images/S4/D09/D09...  \n",
       "3  /data/luiz/dataset/serengeti_images/S1/G12/G12...  \n",
       "4  /data/luiz/dataset/serengeti_images/S5/L05/L05...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/luiz/dataset/partitions/animal-classifier/serengeti/train.csv\n",
      "no     12561\n",
      "yes    12561\n",
      "Name: category, dtype: int64 \n",
      "\n",
      "/data/luiz/dataset/partitions/animal-classifier/serengeti/val.csv\n",
      "yes    3517\n",
      "no     3483\n",
      "Name: category, dtype: int64 \n",
      "\n",
      "/data/luiz/dataset/partitions/animal-classifier/serengeti/test.csv\n",
      "no     4030\n",
      "yes    3970\n",
      "Name: category, dtype: int64 \n",
      "\n",
      "/data/luiz/dataset/partitions/behaviour-classifier/serengeti/train.csv\n",
      "moving     896\n",
      "eating     896\n",
      "resting    896\n",
      "Name: category, dtype: int64 \n",
      "\n",
      "/data/luiz/dataset/partitions/behaviour-classifier/serengeti/val.csv\n",
      "moving     271\n",
      "eating     271\n",
      "resting    271\n",
      "Name: category, dtype: int64 \n",
      "\n",
      "/data/luiz/dataset/partitions/behaviour-classifier/serengeti/test.csv\n",
      "moving     839\n",
      "eating     839\n",
      "resting    839\n",
      "Name: category, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def create_side_by_side_image(batchs):\n",
    "    response = []\n",
    "    for batch in tqdm(batchs):\n",
    "        output_path = f'{SEQUENCE_PATH}{uuid4()}{FILE_TYPE}'\n",
    "\n",
    "        images = [Image.open(img) for img in batch]\n",
    "        min_height = min(img.height for img in images)\n",
    "        resized_images = [\n",
    "            img.resize((int(img.width * min_height / img.height), min_height), Image.Resampling.LANCZOS) for img in images\n",
    "        ]\n",
    "        total_width = sum(img.width for img in resized_images)\n",
    "        combined_image = Image.new(\"RGB\", (total_width, min_height), (255, 255, 255))\n",
    "        x_offset = 0\n",
    "        for img in resized_images:\n",
    "            combined_image.paste(img, (x_offset, 0))\n",
    "            x_offset += img.width\n",
    "        combined_image.save(output_path)\n",
    "        response.append(output_path)\n",
    "    return response\n",
    "\n",
    "def split_data_subsets(df):\n",
    "    unique_locations = df['location'].unique()\n",
    "    np.random.shuffle(unique_locations)\n",
    "    # Define partition ratios\n",
    "    train_ratio = 0.5\n",
    "    val_ratio = 0.15\n",
    "    # Calculate split indices\n",
    "    n_total = len(unique_locations)\n",
    "    train_end = int(train_ratio * n_total)\n",
    "    val_end = train_end + int(val_ratio * n_total)\n",
    "    # Split locations into partitions\n",
    "    train_locations = unique_locations[:train_end]\n",
    "    val_locations = unique_locations[train_end:val_end]\n",
    "    test_locations = unique_locations[val_end:]\n",
    "    # Assign partitions\n",
    "    train = df[df['location'].isin(train_locations)]\n",
    "    val = df[df['location'].isin(val_locations)]\n",
    "    test = df[df['location'].isin(test_locations)]\n",
    "    return balance_dataset(train), balance_dataset(val), balance_dataset(test)\n",
    "\n",
    "def save_results(df, task, filename):\n",
    "    path = f\"{RESULTS_PATH}{task}/{DATABASE}/{filename}\"\n",
    "    print(path)\n",
    "    print(df.category.value_counts(), \"\\n\")\n",
    "    df.to_csv(path, index=False)\n",
    "\n",
    "def save_animal_classifier_dataset(df):\n",
    "    df[\"category\"] = df.path_animal.map(lambda a: \"yes\" if isinstance(a, str) else \"no\")\n",
    "    df = df.rename(columns={\"path_animal\": \"path\"})\n",
    "    df[\"path\"] = df[\"path\"].combine_first(df[\"path_empty\"])\n",
    "    df = df[[\"num_frames\", \"category\", \"location\", \"datetime\", \"path\"]]\n",
    "    train, val, test = split_data_subsets(df)\n",
    "    save_results(train, \"animal-classifier\", \"train.csv\")\n",
    "    save_results(val[:7000], \"animal-classifier\", \"val.csv\")\n",
    "    save_results(test[:8000], \"animal-classifier\", \"test.csv\")\n",
    "\n",
    "\n",
    "def save_behaviour_classifier_dataset(df):\n",
    "    df = df.rename(columns={\"path_animal\": \"path\"})\n",
    "    df = df[[\"num_frames\", \"category\", \"location\", \"datetime\", \"path\", \"path_seq\"]].dropna()\n",
    "    train, val, test = split_data_subsets(df)\n",
    "\n",
    "    train[\"path_seq_saved\"] = create_side_by_side_image(train[\"path_seq\"])\n",
    "    val[\"path_seq_saved\"] = create_side_by_side_image(val[\"path_seq\"])\n",
    "    test[\"path_seq_saved\"] = create_side_by_side_image(test[\"path_seq\"])\n",
    "\n",
    "    save_results(train, \"behaviour-classifier\", \"train.csv\")\n",
    "    save_results(val, \"behaviour-classifier\", \"val.csv\")\n",
    "    save_results(test, \"behaviour-classifier\", \"test.csv\")\n",
    "\n",
    "save_animal_classifier_dataset(df.copy())\n",
    "save_behaviour_classifier_dataset(df.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PASSING IMAGES TO SSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/data/luiz/dataset/partitions/behaviour-classifier/serengeti/val.csv', '/data/luiz/dataset/partitions/behaviour-classifier/serengeti/test.csv', '/data/luiz/dataset/partitions/behaviour-classifier/serengeti/train.csv', '/data/luiz/dataset/partitions/animal-classifier/serengeti/val.csv', '/data/luiz/dataset/partitions/animal-classifier/serengeti/test.csv', '/data/luiz/dataset/partitions/animal-classifier/serengeti/train.csv']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "44120"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def list_all_csv_files(directory):\n",
    "    csv_files = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".csv\"):\n",
    "                csv_files.append(os.path.join(root, file))\n",
    "    return csv_files\n",
    "\n",
    "csv_files = list_all_csv_files(RESULTS_PATH)\n",
    "print(csv_files)\n",
    "ssd_images = []\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    ssd_images.extend(df[\"path\"])\n",
    "\n",
    "ssd_images = list(set(ssd_images))\n",
    "len(ssd_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REPLACE DIR HD TO DIR SSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in [csv_files]:\n",
    "    df = pd.read_csv(file)\n",
    "    df[\"path\"] = df[\"path\"].map(lambda a: a.replace(\"/data/\", \"/ssd/\"))\n",
    "    df.to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COPY IMAGES TO SSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44120/44120 [10:47<00:00, 68.10it/s]\n"
     ]
    }
   ],
   "source": [
    "def copy_images_to_ssd(images):\n",
    "    for file_name in tqdm(list(set(images))):\n",
    "        file_name_ssd = file_name.replace(\"/data/\", \"/ssd/\")\n",
    "        file_name_hd = file_name.replace(\"/ssd/\", \"/data/\")\n",
    "        destination_dir = os.path.dirname(file_name_ssd)\n",
    "        if not os.path.exists(destination_dir):\n",
    "            os.makedirs(destination_dir)\n",
    "        shutil.copy(file_name_hd, file_name_ssd)\n",
    "\n",
    "copy_images_to_ssd(ssd_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ''\n",
    "for i in '1234':\n",
    "    x += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1234'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "luiz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
